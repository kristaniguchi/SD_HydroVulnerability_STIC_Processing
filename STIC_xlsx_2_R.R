#STIC Data Automation for USGS
  #This script takes CSV outputs from various STIC loggers for a given site and replicates the graphics, calculated variables, and summary statistics from the Excel template
  #By Jessica Weidenfeld and Kris Taniguchi-Quan (SCCWRP)


#clear environment - for testing purposes, cleans working environment
rm(list=ls())

#Install required packages (if needed, only need to install once) 
#install.packages("tidyverse")
#install.packages("janitor")
#install.packages("ggplot2")
#install.package("plyr")
#install.packages("dplyr)

#Load required packages (need to load each session)
library(tidyverse)
library(janitor)
library(ggplot2)
library(plyr)


#Set your working directory to be working from (file path where the csv files are located) [USER DEFINED]
csv.directory <- "/Users/ppsp/Desktop/SCCWRP/Kris/USGS Flow/STIC CSV/beaver_hallow/" #update with your file path with csv files


# [USER DEFINED] Set your file path where the csv files are located: location of the folder containing csv files for each site
csv.directory <- "C:/Users/KristineT.SCCWRP2K/SCCWRP/SD Hydro Vulnerability Assessment - General/Data/RawData/USGS_STIC_Data_Hydroperiod/SCCWRP_CSV_test/" #update with your file path with csv files
#csv.directory <- "C:/Users/KristineT/SCCWRP/SD Hydro Vulnerability Assessment - General/Data/RawData/USGS_STIC_Data_Hydroperiod/SCCWRP_CSV_test/" #update with your file path with csv files

#Set working directory to csv.directory

setwd(csv.directory)
#Set output directory where outputs should be saved - subfolder within csv directory
output.directory <- paste0(csv.directory, "Outputs")
#Create output directory (if does not exist already), this creates a new output folder where plots and files to be saved
dir.create(output.directory)

# [USER DEFINED] Define the site name
site.name <- "Beaver_Hollow"

#List the csv files associated with the site (USER DEFINED until lookup table with serial #, date range, and site.name is created)
  #if manually listing csv files for each series, list below in quotes and uncomment next line
  #csv.file.list <- c("", "", "", "", "") 
  #if all files saved in csv.directory are for a given site, then list all files in directory
  csv.file.list <- list.files(csv.directory, pattern=".csv")

# [USER DEFINED] Define thresholds based on %RC-Tc Plots and site for each series data, iterative process could start with defaults then update based on plot1 graphs produced in loop]
#Set Wet/Dry Threshold (%RC): Subjective criterion for what %RC is the minimum for wet readings taking into consideration graphed data and site conditions
  #wetdry_threshold_all is a default list of wet/dry thresholds for each series from 1 to i number of series, if updating threshold for series 1, update first value in list, series 2 is 2nd value in list, etc.
  #User updates these thresholds after evaluting graphed data plot1 from loop, run loop with defaults initially
  #Note: if more than 10 series, add threshold values accordingly to wetdry_threshold_all, percentRCcutoff, and lower_percentRCcutoff
  wetdry_threshold_all <- c(10, 10, 10, 10, 10, 10, 10, 10, 10, 10) 
#Set %RC cutoff and %RC cutoff lower
  #Allows use of upper and lower bounds to limit ringing
  #Default values are set to 0, evaluate cutoff and lower cutoff based on evaluating plot1 from loop, run loop with defaults initially and update as needed
  percentRCcutoff_all <- c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0)
  lower_percentRCcutoff_all <- c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0)
  
  
  
##############################################################################
#loop through each csv file in the directory (series) to be evaluated for given site, make plots and calculations for each series

#first, create empty output dataframe where Summary Stats will be saved from each series
#total number of columns = number of series + 1 (first column is total column)
total.col.num <- length(csv.file.list) + 1
#List of row names (variable names in summary stats)
row_names <- c("RecordSubtotals", "Logger Start Date", "Count of Wet Records", "Count of Dry Records", "% Wet", 
                           "Days Wet", "Days Dry", "Max continuous wet", "MCW Days")
#output summary table blank that each series summary stats will be saved to
SummaryStats.Output <- data.frame(matrix(NA, nrow=length(row_names), ncol=total.col.num))
#set row names in output df
row.names(SummaryStats.Output) <- row_names
#set names of columns (total, series#)
#create list of series numbers 1 to total number of series or csv files
series.list <- paste0("Series ", 1:length(csv.file.list))
#save column names
names(SummaryStats.Output) <- c("Total", series.list)

#create output series_data table containing all calculated variables from each series, start off blank, will add values at end of loop iterations
#column names
series_data_colnames <- c("Date_Time", "Temp_C", "Intensity_Lux",
                           "Date", "STIC_serial", "TempCorrected",      
                           "pct_Rctempcorrected", "Wet_Dry", "Series")
#create empty data frame to save to
series_data_all <- data.frame(matrix(NA, nrow=1, ncol=length(series_data_colnames) ))
#set column names
names(series_data_all) <- series_data_colnames
  
#create output vector combining the WetDry columns from all series - used to calculate total consecutive wet dry record and days
WetDry_all <- NA

#loop through each csv file and series from series i: 1 to length of csv files (series)
for(i in 1:length(csv.file.list)){
  
  #to test out one iteration of loop, do not run for() line above, skip to following line where you set i as an iteration number
  #i=1
  
  ###########################################################################################################
  ####STICs-ALL Data Tab found in xlsx 
  
  #Read in CSV for series i
  csv_data <- read.csv(csv.file.list[i])
  #find original column header names
  orig.colnames <- names(csv_data)
  
  #Clean column names and rename
  csv_data <- csv_data %>%
    clean_names() %>% 
    #rename columns of importance
    dplyr::rename(Date_Time = x,
                  Temp_C=x_1,
                  Intensity_Lux=x_2)

              
  #Remove first row of original unused column names 
  csv_data <- csv_data[-c(1), ]
  
  #Create new data frame using only Date, Temp_C, Intensity_Lux columns from csv
  series_data <- csv_data %>% 
    select(Date_Time,Temp_C,Intensity_Lux) %>% 
    #Create column with date only, removes timestamp
    mutate(Date = as.Date(Date_Time, format = "%m/%d/%y"))
  
  #find logger start date
  logger.start.date <- format(series_data$Date[1], "%m/%d/%y")
  
  #Find the serial number from the original csv first column name which is formatted "i_plot_title_serial#"
  STIC_serial <- gsub("i_plot_title_","",colnames(csv_data)[1])
  #Add serial number as a column to output dataframe
  series_data$STIC_serial <- rep(STIC_serial,length(series_data$Date))
  
  #Convert Temperature from character to numeric format
  series_data$Temp_C <- as.numeric(series_data$Temp_C)
  
  #Calculate mean temp
  Temp_Cmean <- mean(series_data$Temp_C)
  
  #Change temp from F to C if Temp_Cmean is > 35
  series_data <- series_data %>%
    mutate(Temp_C= 
             if(Temp_Cmean > 35){
               ((Temp_C-32)* (5/9))
             }else{
               Temp_C
             }
    )

  
  #Format Intensity_Lux (contains , in values, remove and save as numeric vector) 
  series_data$Intensity_Lux <- gsub(',', '', series_data$Intensity_Lux)
  #Convert Intensity_Lux from character to numeric
  series_data$Intensity_Lux <- as.numeric(series_data$Intensity_Lux)
  
  #attach column names in series_data so you can run analysis by using column name only
  attach(series_data)
  
  #apply function to achieve Temp Corrected value
  series_data <- series_data %>% 
    mutate(TempCorrected = 
             Intensity_Lux/(1+((2.1/100)*((Temp_C)-25)))
           )
  
  #attach(series_data)
  
  #create max temperature corrected variable
  maxTC <- max(series_data$TempCorrected)
  
  #create an equation to use for %RCtempcorrected conditional statements
  temp_equation_1 <- (series_data$TempCorrected/(maxTC*100))
  
  #Set "lower % RCcutoff" and "% RCcutoff" numbers based on user-defined lists outside of loop, ith values associated with series i
  # May need to adjust RC cut offs set outside of loop after looking at "plot1"
  percentRCcutoff <- percentRCcutoff_all[i]
  lower_percentRCcutoff <- lower_percentRCcutoff_all[i]
  
  #Conditional statements to calculate %relative conductivity temp corrected [pct_Rctempcorrected] (note: %Relative conductivity (%RC) uses highest temp corrected raw 'lux' value as 100%)
  series_data <- series_data %>%
    mutate(pct_Rctempcorrected =
             #conditional statement that PLEASE ANNOTATE WHAT THIS IS DOING HERE
             case_when(
               #if temp_equation_1  <= lower_percentRCcutoff, PLEASE ANNOTATE WHAT THIS IS DOING HERE
               temp_equation_1 <= "lower_percentRCcutoff" ~ (TempCorrected/maxTC*100),
               #if temp_equation_1  > percentRCcutoff, PLEASE ANNOTATE WHAT THIS IS DOING HERE
               temp_equation_1 > "percentRCcutoff" ~ (TempCorrected/maxTC*100),
               #PLEASE ANNOTATE WHAT THIS IS DOING HERE
               TRUE ~ as.numeric(TempCorrected, na.rm=TRUE)
             )
    )

  
  ####################################################
  ###Plot timeseries of %RC-temp corrected and Temp C
  #Coefficient to multiply second axis constraints by
  coeff <- .275
  #Colors for lines
  Tempcolor <- "red"
  pct_RCtemp_color <- "blue"
  
  #Creates plot and output
  plot1 <- ggplot(series_data, aes(x=Date)) +
    geom_line( aes(y=Temp_C/coeff, colour="Temperature"),size=1,) + 
    geom_line( aes(y=pct_Rctempcorrected ,  colour="% RC Temp Corrected"),size=1,) +
    scale_y_continuous(sec.axis = sec_axis(~.*coeff, name="Temperature (°C)")) + 
    scale_x_date(date_labels="%m/%d/%y",date_breaks  ="1 month") +
    scale_colour_manual(values = c("blue", "red"), name="") +
    labs(y = "% RC-temp corrected",
         x = "Date") +
    theme_bw() +
    theme(axis.line = element_line(colour = "black"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          legend.position = "top") 
  
  #Print plot
  print(plot1)
  
  #Set file name and save plot as file name
  file.name <- paste0(output.directory,"/", site.name, "_series", i,"_RC_tempcorrected_timeseries_plot", ".png")
  ggsave(plot1, file = file.name, width=10, height=4)
  
  
  ####################################################
  ###Plot timeseries of SpCond-temp corrected and Temp C
  ###JESSICA TO ADD lines to plot sp cond - same as the previous plot just change the left Y axis with spcond
  
  #UPDATE: Coefficient to multiply second axis constraints by
  coeff <- .275
  #Colors for lines
  Tempcolor <- "red"
  pct_RCtemp_color <- "blue"
  
  #UPDATE: Creates plot and output
  plot2 <- ggplot(series_data, aes(x=Date)) +
    geom_line( aes(y=Temp_C/coeff, colour="Temperature"),size=1,) + 
    geom_line( aes(y=pct_Rctempcorrected ,  colour="% RC Temp Corrected"),size=1,) +
    scale_y_continuous(sec.axis = sec_axis(~.*coeff, name="Temperature (°C)")) + 
    scale_x_date(date_labels="%m/%d/%y",date_breaks  ="1 month") +
    scale_colour_manual(values = c("blue", "red"), name="") +
    labs(y = "% RC-temp corrected",
         x = "Date") +
    theme_bw() +
    theme(axis.line = element_line(colour = "black"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          legend.position = "top") 
  
  #Print plot
  print(plot2)
  
  #Set file name and save plot as file name
  file.name2 <- paste0(output.directory,"/", site.name, "_series", i,"_SpCond_timeseries_plot", ".png")
  ggsave(plot2, file = file.name2, width=10, height=4)
  
  
  ####################################################
  #Manually set wet/dry threshold [USER DEFINED in wetdry_threshold_all outside of loop, takes value i for series i]
    #Subjective criterion for what %RC is the minimum for wet readings taking into consideration graphed data (plot1) and site conditions.
  wetdry_threshold <- wetdry_threshold_all[i]
  
  #Create wet_dry column. 0 for dry, 1 for wet 
  series_data <- series_data %>%
    mutate("Wet_Dry"= 
             #ANNOTATE what this is doing
             case_when(Date < 1 ~ (0),
                       #ANNOTATE
                       pct_Rctempcorrected > wetdry_threshold ~ (1),
                       #If true, ANNOTATE
                       TRUE ~ as.numeric(TempCorrected, na.rm=TRUE)
                       )
          )
  
  #save Wet_Dry for series i in output vector WetDry_all
  WetDry_all <- c(WetDry_all, series_data$Wet_Dry)
  
  ###########################################################################################################
  ####Summary Chart ####
  #calculates summary statistics from Serial i saved in SummaryChart tab in xlsx and saves into output dataframe
  
  #Find the number of readings that registers as wet, 
  #but have more than 10 readings in a day (5 hours)
  consecutive_wet <- series_data %>% 
    group_by(Wet_Dry, Date) %>%
    summarise(count = sum(Wet_Dry==1)) %>%
    #Discuss on Monday: where did 10 come from?, got slightly different number 78 instead of 74
    filter(count > 10) 
  
  #Sum the total number of consecutive wet readings, save as numeric
  consecutive_wet <- as.numeric(sum(consecutive_wet$count))

  #Divide the number of wet readings by 48 (since there are 48 readings a day) to get wet days
  #then round the number to nearest whole value
  cons_wet_days <- round_half_up(consecutive_wet/48)
  
  #selects and sums all days that register as wet (Wet_Dry==1)
  count_wet_records <- series_data %>% group_by(Wet_Dry, Date) %>%
    summarise(count = sum(Wet_Dry==1))
  
  #Sum all of the count data together, save as numeric
  count_wet_records <- as.numeric(sum(count_wet_records$count))

  #Total number of recordings (wet and dry) taken by STIC logger, saved as numeric
  RecordSubtotals <- as.numeric(nrow(series_data))
  
  #Calculate total number of recordings that do not register as wet (total minus wet)
  Count_Dry_Records <- (RecordSubtotals - count_wet_records)
  
  #Total number of dry days and rounds to nearest whole number (up and down) - 48 records/day
  Days_Dry <- round_half_up(Count_Dry_Records/48)
  #Selects the maximum number of consecutive wet records --> CHECK consecutive wet value this value, should be 74
  max_continuous_wet <- max(consecutive_wet)
  #Selects maximum continuonus wet days 
  MCW_Days <- max(round_half_up(max_continuous_wet/48))
  
  pct_wet <- round(count_wet_records/(count_wet_records+RecordSubtotals)*100, digits=0)
  
  
  #combine summary stats into a common vector and save into output dataframe
  Summary.Stats <- c(RecordSubtotals, logger.start.date, count_wet_records, Count_Dry_Records, pct_wet, 
                     cons_wet_days, Days_Dry, max_continuous_wet, MCW_Days) 
  
  #save summary stats from series i as column i+1 [reminder: first column is total and will be calculated outside of loop once all series stats generated]
  SummaryStats.Output[,i+1] <- Summary.Stats
  
  #Write csv for series_data output generated for series i 
  file_name3 <- paste0(output.directory,"/SanDiegoSTICsDataProcess_Sets_Series", i, "_", site.name, ".csv")
  write.csv(series_data, file = file_name3, row.names = FALSE)
  
  #save series data in overall output table, add in column with series i
  #series column for output table
  series.i <- rep(paste0("Series ", i), length(series_data[,1]))
  #add series to series_data
  series_data <- series_data %>% 
    mutate(Series = rep(paste0("Series ", i), length(Date_Time)) )
  #append or bind rows from series_data to series_data_all output df
  series_data_all <- rbind(series_data_all, series_data)
  
}


##############################################################################
#Summary Stats across all series

#add totals to the output dataframe (first column that gets total stats)
#Record Subtotals: sum of all series RecordSubtotals
RecordSubtotals <- sum(as.double(SummaryStats.Output[1,]), na.rm=TRUE)
#logger start date blank
logger.start.date <- NA
#sum of remaining variables across all series [rows for each variable in summary table]
count_wet_records <- sum(as.double(SummaryStats.Output[3,]), na.rm=TRUE)
Count_Dry_Records <- sum(as.double(SummaryStats.Output[4,]), na.rm=TRUE)
pct_wet <- sum(as.double(SummaryStats.Output[5,]), na.rm=TRUE)
cons_wet_days <- sum(as.double(SummaryStats.Output[6,]), na.rm=TRUE)
Days_Dry <- sum(as.double(SummaryStats.Output[7,]), na.rm=TRUE)
max_continuous_wet <- NA
MCW_Days <- NA

#combine all values for total column and paste into Summary.Stats.Output
Summary.Stats <- c(RecordSubtotals, logger.start.date, count_wet_records, Count_Dry_Records, pct_wet, 
                   cons_wet_days, Days_Dry, max_continuous_wet, MCW_Days) 
#save summary stats from total as column1 
SummaryStats.Output[,1] <- Summary.Stats

#Max consecutive wet records (on Workspace tab in xlsx), use WetDry_all vector to calculate
max.consec.wet.records.all <- "JESSICA TO UPDATE based on workspace tab equations used"

#Max consecutive wet days (on Workspace tab in xlsx)
max.consec.wet.days.all <- max.consec.wet.records.all / 48



#####################################################################
###Overall %RC and TempC plot for all series - Plot in SummaryChart tab in xlsx
#include logger start/reset (using row 2 from SummaryStats.Output)
#plot data from series_data_all


